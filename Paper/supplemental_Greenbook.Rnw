%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Inflated Expectations
% Cassandra Grafstr√∂m and Christopher Gandrud
% 9 May 2014
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% !Rnw weave = knitr

\documentclass[a4paper]{article}
\usepackage{fullpage}
\usepackage[authoryear]{natbib}
\usepackage{setspace}
    \doublespacing
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=cyan,
    urlcolor=cyan
}
\usepackage{dcolumn}
\usepackage{booktabs}
\usepackage{url}
\usepackage{tikz}
\usepackage{todonotes}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}

% Set knitr global options
<<ParentGlobalOpts, include=FALSE>>=
    # Set root directory. Change if needed for replication.
    opts_knit$set(root.dir = '/git_repositories/Greenbook/')

    opts_chunk$set(concordance=TRUE)
    opts_chunk$set(fig.align='center')
@

<<AnalysisSetUp, include=FALSE>>=
    # Load packages 
    library(apsrtable)
    library(plyr)
    library(xtable)

    # Load data and run the main analyses
    source('Analysis/Greenbook1.R')
    source('Analysis/Greenbook4.R')
@

%%%%%%% Title Page %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{Supplemental Materials for: Inflated Expectations: How government partisanship shapes monetary policy bureaucrats' inflation forecasts}

\author{Christopher Gandrud \\
                {\emph{Hertie School of Governance}}\footnote{Post-doctoral Fellow. Friedrichstra{\ss}e 180. 10117 Berlin, Germany. Email: \href{mailto:gandrud@hertie-school.org}{gandrud@hertie-school.org}.} \\
                and \\
            Cassandra Grafstr\"{o}m \\
                {\emph{University of Michigan}}\footnote{Ph.D Candidate. 5700 Haven Hall, 505 S. State Street
                Ann Arbor, MI 48109-1045. USA. Email: \href{mailto:cgrafstr@umich.edu}{cgrafstr@umich.edu}.} \footnote{Thank you to the Mark Hallerberg and the Fiscal Governance Centre at the Hertie School of Governance for comments and support. Thank you also to Leonardo Baccini, Vincent Arel-Bundock, Mark Kayser, Cheryl Schonhardt-Bailey, Tom Stark, and seminar participants at the Hertie School of Governance, London School of Economics, and Yonsei University as well as two anonymous reviewers.}}

\begin{document}

\maketitle


In the Supplementary Materials we present additional robustness checks to further test the strength of our main empirical findings.

\subsection*{Mid-term election timing}

To further check the robustness of the possible effect of elections on errors we examined models with election variables that included mid-term elections--non-presidential elections when the House of Representatives and a portion of the Senate is elected--in addition to presidential elections. As before, we subsetted the data to exclude quarters when the forecasters would not have known who the winners of the elections would be. This variable was, like the equivalent variable that only included presidential election timing, statistically insignificant. Its interaction with presidential party ID was also insignificant. Table \ref{MidTerm} shows results from two of these models.

\begin{table}[ht]
    \caption{Normal Linear Regression Estimation with Standardized 2 Qrt. Inflation Forecasting Error as the Dependent Variable and a Quarter to Election Variables that Included Midterms (non-matched data set)}
    \label{MidTerm}
    \vspace{0.25cm}
    \begin{center}
    {\small{
<<SupMid, warning=FALSE, echo=FALSE, message=FALSE, results='asis'>>=
    source('Analysis/Greenbook9.R')

    # Model names & Coefficient Names
    ModelNamesSM <- c('SM1', 'SM2')
    CoefNamesSM <- c("Intercept", "Recession", "Expenditure/GDP",
                    "Output Gap", "Discount Rate Change", "Unemployment Rate", "Pres. Party ID",
                    "Qrt. Midterm/Pres. Election", "FRB/GlobalModel", "Senate Dem/Rep", "House Dem/Rep",
                    'Pres*Qrt. Midterm/Pres. Election')

    # Table of non-matched models with ls
    apsrtable(SM1, SM2,
              digits = 1,
              Sweave = TRUE,
              stars = "default",
              model.names = ModelNamesSM,
              coef.names = CoefNamesSM
              )
@
    }}
    \end{center}
\end{table}

\subsection*{President party ID and election timing linear interaction}

In the body of the paper we presented results from models with president party ID and the square of quarters to the election. The first model in Table \ref{SupTable1} shows results with an interaction between president party ID and the non-squared linear version of election timing. The results are substantively equivalent to those with the squared version. In both cases the interaction is not statistically significant.

\subsection*{Economic and violent conflict shocks}

We examined if economic and/or violent conflict shocks may affect inflation forecast errors. First we examined if the underlying level of inflation could impact the standardized forecast errors. Perhaps if price changes are very volatile, e.g. inflation is very high, then there may be larger errors. We examined this possibility by including two absolute inflation variables in the models: (a) the \textbf{absolute inflation level in the quarter being forecasted} for and (b) \textbf{absolute inflation in the quarter prior} to when the forecast was made.\footnote{In Table \ref{SupTable1} this is referred to as `Lag 3 Abs. Inflation'.} The second and third models in Table \ref{SupTable1} show that including these variables did not substantively change the presidential partisan ID results. Absolute inflation in the quarter being forecasted for has a statistically significant negative relationship with forecast errors. Referring back to figures \ref{absolute} and \ref{errors_over_time} in the main paper, this makes empirical sense as periods of high inflation in the 1970s were actually times when the standardized forecast error was relatively small. This finding persists even if we use absolute inflation forecast errors (i.e. $F_{q} - I_{q}$) as the dependent variable. This can be seen in Model S14 in Table \ref{SupTable2}.

We also interacted the absolute inflation variables with presidential party ID. In both cases we estimated that there are small though statistically significant interaction terms. The interaction terms and absolute inflation coefficient estimates are negative, while presidential partisan ID remains positive. Again returning to figures \ref{absolute} and \ref{errors_over_time}, this finding makes sense as the period of high absolute inflation with a Democratic president (Carter) was a time of low standardized forecast errors.

We consider other economic and political shocks. Perhaps oil price shocks, for example in the late 1970s, increased inflation forecast errors. To examine this possibility we gathered data from the FRED database on the \textbf{change in the West Texas Crude price}\footnote{The series ID is OILPRICE. Accessed October 2013.} from the quarter in the previous year to the quarter the inflation forecast was made for. Similarly, maybe labor productivity increases, especially in the 1990s, created unexpected economic conditions that dampened inflation, changing inflation forecasting errors. To examine this possibility we gathered data from the United States Bureau of Labor Statistics on non-farm business \textbf{labor productivity}.\footnote{The series ID was PR85006092. Accessed October 2013.} The variable is in terms of the percent change from the previous quarter at the annual rate. Finally, perhaps violent conflict also created unexpected economic conditions. To examine this we created an indicator of the \textbf{total number of armed conflicts per year that the United States participated in} using data from the Uppsala Conflict Data Program/Peace Research Institute Oslo \citep{Harbom2008,Themner2013}.

We can see in tables \ref{SupTable1} and \ref{SupTable2} that productivity changes were not robustly associated with inflation forecasting errors. Oil price changes were found to be statistically significantly associated with errors. This association was negative so that high price increases are related to lower errors. This mirrors our finding for the absolute inflation level. High absolute inflation and high oil price increases are associated in time during our observation period. They were both particularly high during the mid to late 1970s. This was simultaneously a period of relatively small to negative inflation forecast errors. The number of armed conflicts that the US participated in was found to be significantly negatively associated with inflation forecast errors. This result is being driven by the fact that a long period of inflation under estimates--primarily during George W. Bush's presidency--also was the period where the United States engaged in the most armed conflicts as part of the so-called `War on Terror'. This evidence suggests that Fed staff do not overestimate the effect that price, oil, and armed conflict shocks have on inflation, though they may underestimate their effects.

In Table~\ref{SupTable1} we also included interactions between presidential party ID and the oil price, productivity, and armed conflict shock variables. None of these interactions were estimated to be statistically significant.

Overall, it is important to note that the presidential partisan ID variable's estimated effect largely does not change in magnitude, direction, or statistical significance when the shock variables are included. It also doesn't change when we use our standardized measure or inflation forecasting errors or absolute errors (results shown in Table~\ref{SupTable2}).

\begin{table}[ht]
    \caption{Normal Linear Regression Estimation with Standardized 2 Qtr. Inflation Forecasting Error as the Dependent Variable and Additional Independent Variables (non-matched data set)}
    \label{SupTable1}
    \vspace{0.25cm}
    \begin{center}
    {\tiny{
<<NLSup1, warning=FALSE, echo=FALSE, message=FALSE, results='asis'>>=
    # Model names & Coefficient Names
    ModelNamesS <- c('S1', 'S2', 'S3', 'S4','S5', 'S6', 'S7', 'S8', 'S9',
                    'S10', 'S11')
    CoefNamesS1 <- c("Intercept", "Recession", "Expenditure/GDP",
                    "Output Gap", "Discount Rate Change", "Unemployment Rate", "FRB/GlobalModel", "Senate Dem/Rep",
                    "House Dem/Rep", "Pres. Party ID", "Qtr. to Election",
                    "Pres*Qrt. Election", "Abs. Inflation", 'Pres*Abs. Infl.', "Lag 3 Abs. Inflation",
                    'Pres*Lag 3 Abs. Infl.', "Oil Price Change", 'Pres*Oil Price Change',
                    "Productivity Change", 'Pres*Prod. Change', "No. Armed Conflicts", 'Pres*No. Armed Confl.')

    # Table of non-matched models with ls
    apsrtable(S1, S2, S3, S4, S5, S6, S7, S8, S9, S10, S11,
              digits = 1,
              Sweave = TRUE,
              stars = "default",
              model.names = ModelNamesS,
              coef.names = CoefNamesS1
              )
@
    }}
    \end{center}
\end{table}


\begin{table}[ht]
    \caption{Normal Linear Regression Estimation with Absolute 2 Qtr. Inflation Forecasting Error as the Dependent Variable and Additional Independent Variables (non-matched data set)}
    \label{SupTable2}
    \vspace{0.25cm}
    \begin{center}
    {\tiny{
<<NLSup2, warning=FALSE, echo=FALSE, message=FALSE, results='asis'>>=
    # Model names & Coefficient Names
    ModelNamesS2 <- c('S12', 'S13', 'S14', 'S15','S16', 'S17', 'S18', 'S19')
    CoefNamesS2 <- c("Intercept", "Recession", "Expenditure/GDP",
                    "Output Gap", "Discount Rate Change", "Unemployment Rate",
                    "Pres. Party ID", "Qtr. to Election", "FRB/GlobalModel",
                    "Senate Dem/Rep", "House Dem/Rep", "Pres*Qrt. Election",
                    "Abs Inflation", "Lag 3 Abs. Inflation", "Oil Price Change",
                    "Productivity Change", "No. Armed Conflicts")

    # Table of non-matched models with ls
    apsrtable(S13, S14, S15, S16, S17, S18, S19, S20,
              digits = 1,
              Sweave = TRUE,
              stars = "default",
              model.names = ModelNamesS2,
              coef.names = CoefNamesS2
              )
@
    }}
    \end{center}
\end{table}

\subsection*{Partisan composition of the Federal Reserve Board}

We examined if the partisan composition of the Federal Reserve Board of Governors (BoG) influenced inflation forecast errors. Governors are appointed by the President and approved by the Senate. Perhaps it is the partisan composition of the BoG that Fed Staff are responding to in their forecasts, rather than, or in interaction with, the presidency. To examine these possibilities we added a variable capturing the \textbf{percentage of the BoG appointed by a Democratic president} when the inflation forecasts were made.\footnote{Data on Board membership was taken from the Federal Reserve Board's website at: \url{http://www.federalreserve.gov/aboutthefed/bios/board/boardmembership.htm}. Accessed March 2014.} Results are shown in Table~\ref{BoardPartisan}. We also show results from a model interacting presidential party ID with BoG partisan composition. In the model without an interaction between the BoG partisan composition variable and presidential party ID we do not estimate a statistically significant effect of BoG composition on errors. There is a very weak (both substatntively and statistically significantly) estimated interaction between presidential party ID and BoG partisan composition. The interaction is positive such that inflation forecasts are even higher when there are Democratic presidents with BoG that have more members appointed by Democratic presidents. However, it is important to reiterate that the estimated effect is very small. In sum it appears that the Staff's errors are primarily driven by the president's party ID.

\begin{table}
  \caption{Normal Linear Regression Estimation with Standardized 2 Qtr. Inflation Forecasting Error as the Dependent Variable and Partisan Composition (\% Appointed by a Democratic President) added to the Independent Variables (non-matched data set)}
  \label{BoardPartisan}
  \begin{center}
    {\tiny{
<<SupBoard, warning=FALSE, echo=FALSE, message=FALSE, results='asis'>>=
    # Model names & Coefficient Names
    ModelNamesSBP <- c('S20', 'S21')
    CoefNamesSBP <- c("Intercept", "Recession", "Expenditure/GDP",
                    "Output Gap", "Discount Rate Change", "Unemployment Rate",
                    "FRB/GlobalModel", "Senate Dem/Rep", "House Dem/Rep", "Pres. Party ID",
                    'Partisan Comp. of Fed Board', 'Pres*Partisan Comp. of Fed Board')

    # Table of non-matched models with ls
    apsrtable(S21, S22,
              digits = 1,
              Sweave = TRUE,
              stars = "default",
              model.names = ModelNamesSBP,
              coef.names = CoefNamesSBP
              )
@
    }}
  \end{center}
\end{table}

\subsection*{Orthogonal dependent variable robustness check: Unemployment forecast errors}

<<CreateOrthog, message=FALSE, error=FALSE, warning=FALSE, echo=FALSE>>=
    # Create unempoyment error variable and graph
    source('Analysis/Greenbook10.R')
@

In a further attempt to determine if the results, especially for presidential party ID, are being driven by unobserved time period specific effects that are common to all Federal Reserve Staff forecasts we estimated our analyses with a dependent variable that is orthogonal to inflation forecast errors. The orthogonal variable we examined was {\bf{standardized unemployment rate forecast errors}}.\footnote{Unemployment forecast errors are relatively weakly correlated with inflation forecast errors. The Pearson correlation coefficient for forecasts made two quarters beforehand is \Sexpr{round(Estat, digit = 2)} with a p-value of \Sexpr{round(Pstat, digit = 2)}.} The variable captures the errors Fed Staff make when forecasting the unemployment rate in the same way that the inflation forecast variable measures inflation forecast errors. Unemployment rate forecasts are also reported in the Greenbook. The actual unemployment rate was found using the Federal Reserve's FRED database, as before.\footnote{We focused on 2 quarter forecasts.}

Most of the effects we found using inflation forecast errors were not present or were dramatically smaller in terms of statistical significance and magnitude when unemployment rate errors were the dependent variable.\footnote{The analyses can be fully recreated using source code available at: \url{http://bit.ly/1jKNlYx}.} The lack of a relationship between presidential party ID and unemployment forecast errors is reflected in Figure \ref{Unemployment}. Unlike in Figure \ref{errors_over_time} from the main paper, it is very difficult to find any partisan pattern to the errors. This provides more evidence that the presidential partisan ID effect is a real contributor to Federal Reserve Staff's \emph{inflation} forecasting errors, rather than the observed partisan effect being driven by an unobserved time period specific factor.

This does however raise the question of why there would be a presidential partisan heuristic that is affecting inflation, but not unemployment forecast errors. Presumably a presidential partisan heuristic would also influence expectations about unemployment. As we discuss in the main text, the partisan economic expectations literature suggests that left-leaning Democrats would be believed to enact policies that reduce unemployment, while right-leaning Republicans would be less concerned with this relative to price stability. It is important to note that using a heuristic does not necessarily cause systematic forecasting errors. Systematic errors are expected to \emph{only} occur when the heuristic poorly corresponds to the quantity being forecasted. So it may be that a presidential partisan heuristic for unemployment, to the extent that Fed Staff uses one, more closely correlates with actual differences in how presidents affect unemployment. In other words, it is a rational partisan expectation.

Furthermore, if we compare the magnitude of the inflation and unemployment standardized forecasting errors in the right-panel of Figure \ref{Unemployment} we can see that the range of inflation errors--approximately -0.8 to 0.5--is much larger than the range for unemployment--approximately -0.1 to 0.32, and the maximum overestimate shrinks to about 0.2 if we drop just three unemployment error outliers. This suggests that forecasting unemployment may be less difficult than forecasting inflation. Possibly this is because employment is stickier than prices in that unemployment in one quarter is more closely correlated with unemployment in previous quarters. As the heuristics literature suggests, presidential partisan heuristics would thus be relied on more when forecasting inflation than unemployment because future inflation is more uncertain. If these heuristics only poorly correlate with actual policy differences than the result will be systematic inflation forecasting errors. More work, outside the scope of this paper, is needed to disentangle these possibilities.

%%%%%%%%%%%%%%%%%%%%%%%%%%   Greenbook Unemployment Forecast Error Across Time
\begin{figure}[t]
    \caption{Diagnostics of Unemployment Rate Forecast Error as Orthogonal to Inflation Rate Forecast Errors (1969 - 2007)}
    \label{Unemployment}
    \begin{center}

<<GraphPartisanErrorUnemploy, warning=FALSE, error=FALSE, message=FALSE, echo=FALSE, fig.width=7, fig.height=4, out.width='0.95\\linewidth'>>=
  # Print unemployment error orthogonal graphs
  library(gridExtra)
  grid.arrange(errors.employ.time, ErrorOrthogScatter, ncol = 2)
@

    \end{center}
    \begin{singlespace}
        {\scriptsize{Note: Errors of 0 indicates that inflation/the unemployment rate was perfectly predicted.}}
    \end{singlespace}
\end{figure}

\subsection*{Matching to examine model dependence}

To further examine if our results depend on model specification, rather than an underlying causal effect, we follow recommendations from \cite{Ho2007} to pre-process the data using matching. This data is then used in our parametric regression models to estimate the relationships between our potential causal variables and Fed Staff inflation forecast errors. Doing this allows us to more robustly determine the causal effects of the two `treatments' Fed Staffers are exposed to that we are interested in: a partisan treatment and an electoral treatment.

Pre-analysis matching allows us to mimic the conditions of a randomized experiment. Imagine an ideal world where we could create a controlled experiment to examine the causal relationship between, for example, presidential partisan ID and inflation forecast errors. Following the Neyman-Rubin causal model \citep{Sekhon2008}, estimating causal effects is a comparison between potential outcomes for a hypothetical unit \citep{Stuart2010}. In our study the `unit' is a quarter being forecasted for. The casual effect of presidential party ID on inflation errors is a comparison of the inflation error for the particular quarter when the president is a Democrat and a Republican. We could approach this comparison in an experiment by randomly assigning presidents to quarters. In the language of experimental design the `treatment' could be a Democratic president and the `control' a Republican president. This allows us to have groups of quarters that are as similar as possible except for the president's party ID. Note: in our analysis the determinations of `treatment' and `control' groups is arbitrary.

This is clearly impossible for us. Given that we are working with observational data, other variables that have an impact on forecast errors may have {\emph{different distributions}} across the treatment and control groups \citep{Cochran1973, Diamond2012}. It can be difficult to identify the relationships between presidential party ID, elections, and errors from all of the confounding background variables.

Thus far we have attempted to address this issue statistically with models that allow us to estimate the effect of presidential party ID and elections on forecast errors `controlling for' a wide variety of other factors. However, it may be the case that our results are dependent on the model specifications \citep{Ho2007}. To examine this possibility we aimed to further recreate randomized experimental conditions with pre-analysis matching. We use the {\tt{R}} package {\tt{MatchIt}} \citep{matchit2011} to create two matched data sets where the non-treatment covariates in the control groups closely match those in the treatment groups.

Formally, each quarter $q$ in the data set is `assigned' to either the treatment group ($t_{q} = 1$) or the control group ($t_{q} = 0$). $y_{q}(1)$ is the potential outcome--in our case the inflation forecast error--for quarter $q$ of being in the treatment group, regardless of whether or not it was observed to be in this group. $y_{q}(0)$ is the potential outcome if $q$ was not in the treatment group, regardless of its observed assignment. It is impossible to observe both $y_{q}(1)$ and $y_{q}(0)$ at the same time. Instead we observe one version of $y_{q}=t_{q}y_{q}(1)-(1-t_{q})y_q(0)$. For each $q$ there is a fixed vector of exogenous confounders $X_{q}$. Ideally $t_{q}$ and $X_{q}$ are independent. However, this is not necessarily the case. The point of matching is to reduce or eliminate the relationship between $t_{q}$  and $X_{q}$ by selecting, dropping, and/or duplicating data. Ideally this process matches one treated quarter with one controlled quarter that has the same values of $X_{q}$, i.e. the distribution of covariates is the same in the treated and control groups \citep{matchit2011}. This is known as ``covariate balance" \cite[1]{Diamond2012}. Using matching to balance a data set ``break[s] the link between the treatment variables and the pre-treatment controls'', effectively replicating the conditions of a randomized experiment with observational data \cite[][2--3]{matchit2011}.

Balance is usually achieved in matching with propensity scores: the probabilities that units were assigned the treatment given their covariates. The propensity score model is generally unknown \citep{Drake1993}. To find the propensity score model we use Diamond and Sekhon's \citeyearpar{Diamond2012} genetic matching method (GenMatch).\footnote{The method is implemented with {\tt{MatchIt}}. The original source code for our exact matching models can be found at {\url{http://bit.ly/1gWPhw9}}.} GenMatch is a multivariate method that uses an evolutionary search algorithm to automate the search for the propensity score model that creates maximum balance. This minimizes the difficulty of ``manually and iteratively checking the propensity score" to determine covariate balance \citep[][2]{Diamond2012}.

Once we created the matched data sets we then used them in parametric models similar to those above. See results in tables \ref{OutputEL}, \ref{OutputPL}, and \ref{OutputPB}.

Before discussing the results, let's examine diagnostic tests we ran on the matching models. We primarily diagnosed the matching models with propensity score distribution plots--the probability of a quarter being in the `treated' group given its covariates--as well as quantile-quantile plots to diagnose whether or not each covariate in the matched data sets is balanced \citep{Ho2007}. Please see figures \ref{ElectPropensityScores} and \ref{PresPropensityScores} for the propensity score distributions in our matched data sets. The quantile-quantile plots are not shown, but can easily be created by running the original matching models in our main analysis source code file. The file is available at: \url{http://bit.ly/1gWPhw9}. We are unable to achieve covariate balance for the Congressional interaction terms\footnote{The presidential party ID and election period interaction does balance.} and the Federal Reserve Chair variable. Chairs in our data set in the pre-Volcker/Greenspan era as well as current Chair Ben Bernanke were in office for very few observed quarters, making it difficult to match them. As such, we were not able to test the robustness of our findings for these variables with matched data.

Overall the results are similar when we use matched and non-matched data. The main difference is that the standard errors are larger in models using matched data than unmatched data. See Figure \ref{CoefComparePlots2} for the implications of the larger standard errors. Larger variance is likely because the matched data sample sizes are smaller.

Nonetheless both the point estimates and the uncertainty surrounding our key presidential partisan ID variable are very similar using both matched and non-matched data. We also did not find evidence that inflation forecast errors were associated with elections either independent of presidential party ID or in interaction with it in the matched models, including when we matched based on election period. This provides more evidence that our results are robustly estimating an actual causal effect and are not model dependent.

%%%%%%% Table of  matched data with Normal Linear parametric model %%%%%%%%

\begin{table}[ht]
    \caption{Normal Linear Regression Estimation of Covariate Effects on 2 Qtr. Inflation Forecast Error (Matched by Election Period Variable)}
    \label{OutputEL}
    \vspace{0.25cm}
    \begin{center}
    {\tiny
<< ELTables, warning=FALSE, echo=FALSE, message=FALSE, results='asis'>>=

    # Model names & Coefficient Names -- Use B for all  matched models
    ModelNamesB <- c("B1", "B2", "B3", "B4", "B5", "B6", "B7", "B8", "B9", "B10", "B11", "B12", "B13")
    CoefNamesB <- c("Intercept", "Expenditure/GDP", "Output Gap", "Discount Rate Change", "Unemployment Rate", "Qtr. to Election", "Qrt. to Election2", "Election Period", "Pres. Party ID", "Deficit/GDP", "FRB/GlobalModel",  "Senate Dem/Rep", "House Dem/Rep", "Pres*Qrt. Election", "Pres*Qrt. Election2", "Pres*House", "Pres*Senate", "House*Senate", "Pres*House*Senate")

    # Table of non-matched models with ls
    apsrtable(EL1, EL2, EL3, EL4, EL4.1, EL5, EL6, EL7, EL8, EL9, EL10, EL11, EL12,
              digits = 1,
              Sweave = TRUE,
              stars = "default",
              model.names = ModelNamesB,
              coef.names = CoefNamesB,
              notes = list(se.note,
                           stars.note,
                           "The recession variable is omitted because there was almost no variation in the matched data set.",
                           "The reason that there was no variation is because there were only two quarters with both a recession",
                           "and an election period in our data set."
                           )
              )

@
    }
    \end{center}
\end{table}

%%%%%%% Table of pres_party matched data with Normal Linear Regression parametric model %%%%%%%%

\begin{table}[ht]
    \caption{Normal Linear Regression Estimation of Covariate Effects on 2 Qtr. Inflation Forecast Error (Matched by President's Party ID variable)}
    \label{OutputPL}
    \vspace{0.25cm}
    \begin{center}
    {\tiny
<< PLTables, warning=FALSE, echo=FALSE, message=FALSE, results='asis'>>=

    # Model names & Coefficient Names -- Use C for all  matched models
    ModelNamesC <- c("C1", "C2", "C3", "C4", "C5", "C6", "C7", "C8", "C9", "C10", "C11", "C12", "C13")
    CoefNamesC <- c("Intercept", "Recession", "Expenditure/GDP", "Output Gap", "Discount Rate Change", "Unemployment Rate", "Qtr. to Election", "Qrt. to Election2", "Election Period", "Pres. Party ID", "Deficit/GDP", "FRB/GlobalModel", "Senate Dem/Rep", "House Dem/Rep", "Pres*Qrt. Election", "Pres*Qrt. Election2", "Pres*House", "Pres*Senate", "House*Senate", "Pres*House*Senate")

    # Table of non-matched models with ls
    apsrtable(PL1, PL2, PL3, PL4, PL4.1, PL5, PL6, PL7, PL8, PL9, PL10, PL11, PL12,
              digits = 1,
              Sweave = TRUE,
              stars = "default",
              model.names = ModelNamesC,
              coef.names = CoefNamesC
              )

@
    }
    \end{center}
\end{table}

%%%%%%% Table of pres_party matched data with Normal Bayesian linear parametric model %%%%%%%%

<< PBTables, warning=FALSE, echo=FALSE, message=FALSE, results='asis'>>=
# Get the model summary
PB1Summary <- summary(PB1)
PB1Summary <- data.frame(PB1Summary$summary)

# Clean up variable names
PB1Summary <- rename(PB1Summary, c(X2.5. = "2.5%"))
PB1Summary <- rename(PB1Summary, c(X50. = "50%"))
PB1Summary <- rename(PB1Summary, c(X97.5. = "97.5%"))

# Clean up Covariate Labels
Variables <- c("Intercept", "Pres. Party ID", "Recession", "Qtr. to Election", "Expenditure/GDP", "Output Gap", "Discount Rate Change", "Unemployment Rate", "Global Model", "sigma2")

PB1Summary <- cbind(Variables, PB1Summary)

print.xtable(xtable(PB1Summary, caption = "Bayesian Normal Linear Regression Estimation of Covariate Effects on 2 Qtr. Inflation Forecast Error (Matched by President's Party ID variable)", label = "OutputPB", align = c("l", "l", "c", "c", "c", "c", "c")), caption.placement = getOption("xtable.caption.placement", "top"), size = getOption("xtable.size", "small"), include.rownames = FALSE)
@

%%%%%%% Matching Diagnostic Plots %%%%%%
%%%%% Elections %%%%%%%
\begin{figure}[h]
  \caption{Matched on Election Period}
  \label{ElectPropensityScores}
 <<ElectPropensity, echo=FALSE, fig.height=4>>=
 plot(cpi.matched.election, type = "jitter", interactive = FALSE)
@
    \begin{singlespace}
        {\scriptsize{Pre- and Post-matching propensity scores, where the ``Treated Units" are election quarters or the quarter before. ``Control Units" are from all other quarters. The more similar the distribution of matched treated and control unit propensity scores, the more successful the matching model was \cite[17]{Hollyer2012}.}}
    \end{singlespace}
\end{figure}

%%%%% Presidential Party ID %%%%%%
\begin{figure}[h]
  \caption{Matched on Presidential Party Identification}
  \label{PresPropensityScores}
<<PresPropensity, echo=FALSE, fig.height=4>>=
plot(cpi.matched.party, type = "jitter", interactive = FALSE)
@
  \begin{singlespace}
      {\scriptsize{Pre- and Post-matching propensity scores, where the ``Treated Units" are quarters when the president was a Democrat. ``Control Units" are quarters when with a Republican president. The more similar the distributions of matched treated and control unit propensity scores, the more successful the matching model was \cite[17]{Hollyer2012}.}}
  \end{singlespace}
\end{figure}

\begin{figure}[t]
    \caption{95\% Confidence Bands for Coefficients from a Variety of Matching and Parametric Model Specifications}
    \label{CoefComparePlots2}
    \begin{center}

<<CoefComparePlotsMatched, warning=FALSE, echo=FALSE, message=FALSE, results='hide', fig.height=4, out.width='0.95\\linewidth'>>=
    # Load model objects created earlier
    load("Paper/ModelObjects.RData")

    # Create plots
    source('Analysis/Greenbook11.R')
@
    \end{center}
    \begin{singlespace}
        {\scriptsize{Data matched by presidential party identification. Intercept values are not shown to maintain a reasonable scale for comparing covariate estimates.}}
    \end{singlespace}
\end{figure}

\subsection*{A brief history of inflation forecasting models at the US Federal Reserve (1970-2013)}

Beginning in 1970 the Federal Reserve\footnote{As before, this discussion draws heavily on Brayton et al.'s \citeyear{Brayton1997} detailed description of the changes to Federal Reserve forecasting models that took place in 1996.} implemented its first comprehensive statistical forecasting model of US Economy, generally known as the MPS.\footnote{MPS stands for MIT-Penn-SSRC, the economics departments associated with the original contributors to the model used by the Fed.} This model contained 60 behavioral equations solved simultaneously in which short-run dynamics were based on an IS/LM/Phillips Curve paradigm while long-run dynamics were given by the neoclassical growth model of production, factor demands, and consumption. In 1975, the Fed responded to the first oil shock and the dissolution of Bretton Woods by creating the Multi-Country Model (MCM) to estimate economic inter-dependencies between the US and other major economic powers. The MCM contained over 200 behavioral equations and was based on similar assumptions about the relationship between inflation and unemployment, and so on as the MPS model. Expectations in both the MPS and the MCM were modeled as adaptive and often subsumed through independent variable lags. The use of adaptive expectations meant that actors were inherently backward-looking, incorporating old information into future behavior, but failing to account for expected future outcomes in current behavior. Adaptive expectations would be the defining feature of Federal Reserve forecasts through 1995 \citep[45]{Brayton1997}. Equations and variables were changed over the 25 years that the MPS and MCM models were in use to adjust for new macroeconomic knowledge, but these changes did not alter the basic structure of the models. Furthermore, these minor changes were incremental and not documented in a unified framework, at least not in a way that is accessible to researchers. Attempts to account for these minor changes explicitly in our models would be at best atheoretical and at worst impossible.

It wasn't until 1996 that the fundamental assumptions of the model were changed in response to the rise of rational expectations theories in economics. The incorporation of rational expectations into the forecasts required a completely new set of models that are self-referential and internally consistent. That is, predictions made by the model are used as expected outcomes in other equations in an iterative manner until estimates converge. Market actors in these new models (FRB/US and FRB/Global) are forward-looking: making investment, spending, and production decisions based on expectations of future economic outcomes. The adjustments they make to their behavior in response to these expectations then alter likely outcomes, which must then be accounted for in the estimates, and so on. The fundamental difference between the MPS-MCM and FRB/US-FRB/Global frameworks is that while the older forecasting models assumed that market participants would extrapolate recent economic outcomes into the future, the new models assume that actors respond strategically to these extrapolations by altering their behavior which can in turn alter expected outcomes.


%%%%%%% References %%%%%%%%%%%%

\clearpage

\bibliographystyle{apsr}
\bibliography{GreenBook.bib}

\end{document}
